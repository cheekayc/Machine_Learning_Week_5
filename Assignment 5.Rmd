---
title: "Assignment 5"
author: "Chee Kay Cheong"
date: "2023-02-14"
output: github_document
---

```{r setup, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, set.seed(123))

library(tidyverse) 
library(caret) 
library(glmnet)
```

# Load and clean dataset, data partitioning

```{r}
# Load and clean dataset
alcohol = read_csv("./Data/alcohol_use.csv") %>%  
  janitor::clean_names() %>% 
  select(-x1) %>% 
  mutate(
    alc_consumption = as_factor(alc_consumption),
    alc_consumption = relevel(alc_consumption, ref = "NotCurrentUse"))

# Check the distribution of the outcome
alcohol %>% 
  select(alc_consumption) %>% 
  group_by(alc_consumption) %>% 
  count()
# Quite balance...

# Partition data into 70/30 split
set.seed(123)

train_index = 
  alcohol$alc_consumption %>% createDataPartition(p = 0.7, list = F)

train_data = alcohol[train_index, ]
test_data = alcohol[-train_index, ]
```

# 1. Create 3 different models

### Elastic Net Model

```{r}
set.seed(123)

# Set validation method and options
control.settings = trainControl(method = "repeatedcv", number = 10, repeats = 10)

# Fit model
EN_model = train(alc_consumption ~ ., data = train_data, method = "glmnet", trControl = control.settings, preProc = c("center", "scale"), tuneLength = 10)

# Find best tuned parameters
EN_model$bestTune

EN_model$results
# Highest accuracy = 0.8515189, Kappa = 0.6956916, alpha = 0.7, lambda = 0.2578427450
```

Professor's solution:
```{r}
set.seed(123)

# Create vectors of lambda and alpha
lambda = 10^seq(-3, 3, length = 100)
alpha = 0.1*seq(1, 10, length = 10)

# Create Model 1 using `Caret`
model.1 = train(alc_consumption ~ ., data = train_data, method = "glmnet", trControl = trainControl("cv", number = 10), preProcess = c("center", "scale"), tuneGrid = expand.grid(alpha = alpha, lambda = lambda))

# Output best values of alpha & lambda
model.1$finalModel$tuneValue
model.1$bestTune

# Can store it if we want to use in a different implementation
best.alpha = model.1$bestTune$alpha
best.lambda = model.1$bestTune$lambda

# To view coefficients, must specify value of lambda
coef(model.1$finalModel, model.1$bestTune$lambda)
model.1$results[which.max(model.1$results$Accuracy), ] # find where the maximum accuracy is and print that row out.

# OR

max(model.1$results$Accuracy)

# OR

confusionMatrix(model.1)
```
How to interpret ConfusionMatrix?
53.3% of the data is correctly classified as those who are "CurrentUse" has been predicted as "CurrentUse".
33 % of the data is correctly classified as those who are "NotCurrentUse" has been predicted as "NotCurrentUse".
13.8% of the data has been **misclassified** because 13.8% of the "NotCurrentUse" has been predicted as "CurrentUse".

### Traditional Logistic Regression

**If we still want to use `glmnet` we must set alpha and lambda equal to 0, so that it gives us a traditional logistic regression.**
```{r}
set.seed(124)

# Set validation method and options
control.settings = trainControl(method = "repeatedcv", number = 10, repeats = 10)

# Fit model
logreg = train(alc_consumption ~ ., data = train_data, method = "glmnet", family = 'binomial', trControl = control.settings, preProc = c("center", "scale"), tuneLength = 10) 

# Find best tuned parameters
logreg$bestTune

logreg$results
# Highest accuracy = 0.8515188, Kappa = 0.6956381, alpha = 0.7, lambda = 0.2578427450
```

Professor's solution:
```{r}
set.seed(123)

model.2 = train(alc_consumption ~ ., data = train_data, method = "glm", trControl = trainControl("cv", number = 10), preProcess = c("center", "scale"))

model.2$results
coef(model.2$finalModel) # Nothing gets shrunk down to 0, but we still get to see variable importance.

confusionMatrix(model.2)
# Average accuracy = 0.8045
```

We can see that although we have a lower overall accuracy and there is some misclassification of "CurrentUse", but we are doing much better with the "NotCurrentUse" prediction. 
**So there is a balance in traditional logistic regression.**


### LASSO Model

```{r}
set.seed(125)

lambda.2 = 10^seq(-3, 1, length = 100)
lambda.grid = expand.grid(alpha = 1, lambda = lambda.2)

lasso = train(alc_consumption ~ ., data = train_data, method = "glmnet", preProc = c("center", "scale"), trControl = control.settings, tuneGrid = lambda.grid)

# Find best tuned parameters
lasso$bestTune

lasso$results
# Highest accuracy = 0.8515234, Kappa = 0.6957193637, alpha = 1, lambda = 0.242012826
```

Professor's Solution:
```{r}
set.seed(123)

model.3 = train(alc_consumption ~ ., data = train_data, method = "glmnet", trControl = trainControl("cv", number = 10), preProcess = c("center", "scale"), tuneGrid = expand.grid(alpha = 1, lambda = lambda))

# Output best value of alpha & lambda
model.3$finalModel$tuneValue
model.3$bestTune

confusionMatrix(model.3)

coef(model.3$finalModel, model.3$bestTune$lambda)
```


# 2. Decide final model

Based on the performance tests of all three models, I decided to use the **LASSO** model because it has the highest accuracy (0.8515234), as well as the highest Kappa value (0.6957193637), among all three models. The best tune of the LASSO model is lambda equals 0.242012826. 

* The **Kappa** value is a metric that compares an *Observed Accuracy* with an *Expected Accuracy* (random chance). The kappa statistic is used not only to evaluate a single classifier, but also to evaluate classifiers amongst themselves. It is a measurement of the accuracy of a model while taking into account chance. The closer the value is to 1 the better.
  - Cited: rbx (https://stats.stackexchange.com/users/37276/rbx), Cohen's kappa in plain English, URL (version: 2017-10-29): https://stats.stackexchange.com/q/82187


# 3. Apply final model in the test set

I decided to use Confusion Matrix as my final evaluation metric.

```{r}
# Test model
test_outcome = predict(lasso, test_data)

# Evaluation metric:
confusionMatrix(test_outcome, test_data$alc_consumption, positive = "CurrentUse")
```

# Report Analysis and Results

Before conducting any analysis, I cleaned the `alcohol_use` dataset and checked the distribution of the outcome (`alc_consumption`). The proportion of `*CurrentUse*` is 0.53, while the proportion of `*NotCurrentUse*` is 0.47. I think they are pretty balance so I decided not to down sample the outcome during `trainControl`. I partitioned the dataset into a 70/30 split.

To better predict the current alcohol consumption, I have created and compared three different models (Elastic Net, Logistic Regression, and LASSO). Among the three models, LASSO gives the highest accuracy (0.8515234) and Kappa value (0.6957193637). The best tune lambda of this model is 0.242012826. 

I then fit the LASSO model to the testing dataset to test its performance. It turned out that this model has an accuracy of 85.5%, with a sensitivity of 1, a specificity of 0.69, a positive predictive value of 0.7859, and a negative predictive value of 1.


# Problem 5

Assuming we have a another 2000 participants who had taken the behavioral test but did not answer whether they currently consume alcohol or not. We can use this analysis to directly predict the current alcohol consumption for this group of people using their test scores. On another instance, if we were interested in seeking the association between alcohol consumption and liver cancer among this population, this analysis can indirectly provide information about the prediction of alcohol consumption of each individual in this population.  

